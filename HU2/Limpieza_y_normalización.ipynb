{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f4ead37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ciudad       fecha producto      tipo_producto  cantidad  \\\n",
      "0                santiago  2025-10-30    arepa          abarrotes       2.0   \n",
      "1                 cordoba  2025-11-17    arepa          abarrotes       7.0   \n",
      "2            barranquilla  2025-10-22    leche             lacteo       9.0   \n",
      "3                new york  2025-10-20   cereal             lacteo       3.0   \n",
      "4                  madrid  2025-10-20    leche              hogar       2.0   \n",
      "...                   ...         ...      ...                ...       ...   \n",
      "1048570       guadalajara  2025-10-23   yogurt             lacteo       9.0   \n",
      "1048571  ciudad de mexico  2025-11-13  gaseosa              hogar       7.0   \n",
      "1048572              lima  2025-10-30    arepa             bebida       8.0   \n",
      "1048573            madrid  2025-10-23     cafe          abarrotes      10.0   \n",
      "1048574             cusco  2025-10-22    queso  alimentopercedero       1.0   \n",
      "\n",
      "         precio_unitario tipo_de_venta tipo_cliente  descuento  costo_envio  \\\n",
      "0                 3681.0        online    minorista       0.20          0.0   \n",
      "1                 2321.0  distribuidor     gobierno       0.15          0.0   \n",
      "2                 3540.0  distribuidor     gobierno       0.20          0.0   \n",
      "3                 3287.0  tiendafisica     gobierno       0.05          0.0   \n",
      "4                 3414.0  distribuidor    mayorista       0.00          0.0   \n",
      "...                  ...           ...          ...        ...          ...   \n",
      "1048570           4325.0        online    mayorista       0.05          0.0   \n",
      "1048571           1187.0  tiendafisica     gobierno       0.15          0.0   \n",
      "1048572           3575.0           NaN  corporativo       0.10          0.0   \n",
      "1048573           2073.0        online  corporativo       0.00          0.0   \n",
      "1048574           1192.0    callcenter    minorista       0.00          0.0   \n",
      "\n",
      "         total_venta  \n",
      "0            5889.60  \n",
      "1           13809.95  \n",
      "2           25488.00  \n",
      "3            9367.95  \n",
      "4            6828.00  \n",
      "...              ...  \n",
      "1048570     36978.75  \n",
      "1048571      7062.65  \n",
      "1048572     25740.00  \n",
      "1048573     20730.00  \n",
      "1048574      1192.00  \n",
      "\n",
      "[1048575 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "df_test = pd.read_csv(\"../ventas_limpias.csv\")\n",
    "\n",
    "print(df_test)\n",
    "# [1.048.574  rows x 11 columns]\n",
    "# 11 Columnas\n",
    "# 1.048.575 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bcabc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Succesfull!!\n"
     ]
    }
   ],
   "source": [
    "#Carga el archivo .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "#Variables de entorno\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(URL)\n",
    "\n",
    "conn = engine.connect()\n",
    "try:\n",
    "    print(\"Connection Succesfull!!\" if conn else \"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error al conectar la base datos en\", e)\n",
    "    \n",
    "set = conn.execute(text(\"SET search_path TO riwi_ventas\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb08dbf",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a1b0e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Succesfull!!\n",
      "\n",
      "=== Procesando tabla: tipo_producto ===\n",
      "[tipo_producto] Filas originales: 7, Filas limpias: 7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CursorResult' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# identificar IDs eliminados\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m deleted_ids = \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moriginal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mset\u001b[39m(clean_df[pk])\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# borrar filas sucias\u001b[39;00m\n\u001b[32m    124\u001b[39m delete_rows(table, pk, deleted_ids)\n",
      "\u001b[31mTypeError\u001b[39m: 'CursorResult' object is not callable"
     ]
    }
   ],
   "source": [
    "#Carga el archivo .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "#Variables de entorno\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(URL)\n",
    "\n",
    "conn = engine.connect()\n",
    "try:\n",
    "    print(\"Connection Succesfull!!\" if conn else \"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error al conectar la base datos en\", e)\n",
    "    \n",
    "set = conn.execute(text(\"SET search_path TO riwi_ventas\"))\n",
    "\n",
    "table_list = pd.read_sql(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'riwi_ventas';\"),conn)\n",
    "\n",
    "# def cleaner(table):\n",
    "#     dinamic_df = pd.read_sql(text(f\"select * from riwi_ventas.{table}\"),conn)\n",
    "\n",
    "#     dinamic_df = dinamic_df[dinamic_df.isnull().mean(axis=1) <= 0.50]\n",
    "#     a = dinamic_df.columns\n",
    "#     a.tolist()\n",
    "\n",
    "#     false_count = 0\n",
    "#     for c in a:\n",
    "#         if c ==False:\n",
    "#             false_count +=1\n",
    "#     print(\"Hay: \",false_count, \" datos nulos\")\n",
    "#     return dinamic_df\n",
    "\n",
    "def cleaner(table, conn):\n",
    "    original_df = pd.read_sql(text(f'SELECT * FROM riwi_ventas.\"{table}\"'), conn)\n",
    "\n",
    "    clean_df = original_df[original_df.isnull().mean(axis=1) <= 0.50]\n",
    "\n",
    "    print(f\"[{table}] Filas originales: {len(original_df)}, Filas limpias: {len(clean_df)}\")\n",
    "\n",
    "    return original_df, clean_df\n",
    "\n",
    "# for i in range(len(table_list)):\n",
    "#     df = cleaner(table_list[\"table_name\"][i],conn)\n",
    "#     print(f\"{table_list['table_name'][i]}: {df.columns.tolist()}\\n\")\n",
    "\n",
    "def get_primary_key(table):\n",
    "    query = text(f\"\"\"\n",
    "        SELECT a.attname AS pk\n",
    "        FROM pg_index i\n",
    "        JOIN pg_attribute a \n",
    "            ON a.attrelid = i.indrelid \n",
    "           AND a.attnum = ANY(i.indkey)\n",
    "        WHERE i.indrelid = 'riwi_ventas.\"{table}\"'::regclass\n",
    "          AND i.indisprimary;\n",
    "    \"\"\")\n",
    "    \n",
    "    result = conn.execute(query).fetchone()\n",
    "\n",
    "    return result[0] if result else None\n",
    "\n",
    "def delete_rows(table, pk, ids):\n",
    "    if not ids:\n",
    "        print(\"No hay IDs para eliminar.\")\n",
    "        return\n",
    "\n",
    "    query = text(f\"\"\"\n",
    "        DELETE FROM riwi_ventas.\"{table}\"\n",
    "        WHERE {pk} = ANY(:ids)\n",
    "    \"\"\")\n",
    "\n",
    "    conn.execute(query, {\"ids\": list(ids)})\n",
    "    print(f\"✔ Eliminadas {len(ids)} filas.\")\n",
    "\n",
    "def insert_clean_rows(table, df):\n",
    "    if df.empty:\n",
    "        print(\"No hay filas limpias para insertar.\")\n",
    "        return\n",
    "\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    colnames = \", \".join([f'\"{c}\"' for c in cols])\n",
    "    placeholders = \", \".join([f\":{c}\" for c in cols])\n",
    "\n",
    "    query = text(f\"\"\"\n",
    "        INSERT INTO riwi_ventas.\"{table}\" ({colnames})\n",
    "        VALUES ({placeholders})\n",
    "    \"\"\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        conn.execute(query, row.to_dict())\n",
    "\n",
    "    print(f\"✔ Insertadas {len(df)} filas limpias.\")\n",
    "\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "\n",
    "    for table in table_list[\"table_name\"]:\n",
    "\n",
    "        print(f\"\\n=== Procesando tabla: {table} ===\")\n",
    "\n",
    "        original_df, clean_df = cleaner(table, conn)\n",
    "\n",
    "        # obtener primary key\n",
    "        pk = get_primary_key(table)\n",
    "\n",
    "        if pk is None:\n",
    "            print(f\"No PK en tabla {table}, saltando…\")\n",
    "            continue\n",
    "\n",
    "        # identificar IDs eliminados\n",
    "        deleted_ids = set(original_df[pk]) - set(clean_df[pk])\n",
    "\n",
    "        # borrar filas sucias\n",
    "        delete_rows(table, pk, deleted_ids)\n",
    "\n",
    "        # reinsertar las filas limpias\n",
    "        insert_clean_rows(table, clean_df)\n",
    "\n",
    "        print(f\"✔ Tabla {table} actualizada correctamente.\")\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_sql(text(\"SELECT * FROM factura_ventas;\"), conn)\n",
    "# #dfc = pd.read_sql(text(\"select * from ciudad;\"),conn)\n",
    "\n",
    "# cols = df.columns.to_list()\n",
    "\n",
    "# # a = dfc[\"nombre_ciudad\"].notnull()\n",
    "# # a.tolist()\n",
    "\n",
    "# false_count = 0\n",
    "# for c in a:\n",
    "#     if c ==False:\n",
    "#         false_count +=1\n",
    "# print(\"Hay: \",false_count, \" datos nulos\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ba50617",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceClosedError",
     "evalue": "This Connection is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceClosedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m table_list = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT table_name FROM information_schema.tables WHERE table_schema = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mriwi_ventas\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m current_schema = pd.read_sql(\u001b[33m\"\u001b[39m\u001b[33mSHOW search_path;\u001b[39m\u001b[33m\"\u001b[39m, conn)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(current_schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/pandas/io/sql.py:736\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_table(\n\u001b[32m    727\u001b[39m         sql,\n\u001b[32m    728\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    733\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    734\u001b[39m     )\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/pandas/io/sql.py:1848\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1793\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1800\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1801\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1802\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1804\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1846\u001b[39m \n\u001b[32m   1847\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1848\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1849\u001b[39m     columns = result.keys()\n\u001b[32m   1851\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/pandas/io/sql.py:1672\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.exec_driver_sql(sql, *args)\n\u001b[32m-> \u001b[39m\u001b[32m1672\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:526\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1641\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1629\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1630\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1631\u001b[39m )\n\u001b[32m   1633\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1634\u001b[39m     dialect=dialect,\n\u001b[32m   1635\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1639\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1640\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1655\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1656\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1660\u001b[39m         ret,\n\u001b[32m   1661\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1813\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1811\u001b[39m     conn = \u001b[38;5;28mself\u001b[39m._dbapi_connection\n\u001b[32m   1812\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1813\u001b[39m         conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_revalidate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1815\u001b[39m     context = constructor(\n\u001b[32m   1816\u001b[39m         dialect, \u001b[38;5;28mself\u001b[39m, conn, execution_options, *args, **kw\n\u001b[32m   1817\u001b[39m     )\n\u001b[32m   1818\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (exc.PendingRollbackError, exc.ResourceClosedError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/andres_p/Analisis-de-Datos-Python-Power-BI/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:676\u001b[39m, in \u001b[36mConnection._revalidate_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[38;5;28mself\u001b[39m.engine.raw_connection()\n\u001b[32m    675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dbapi_connection\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc.ResourceClosedError(\u001b[33m\"\u001b[39m\u001b[33mThis Connection is closed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mResourceClosedError\u001b[39m: This Connection is closed"
     ]
    }
   ],
   "source": [
    "table_list = pd.read_sql(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'riwi_ventas';\"),conn)\n",
    "\n",
    "current_schema = pd.read_sql(\"SHOW search_path;\", conn)\n",
    "print(current_schema)\n",
    "\n",
    "def cleaner(table):\n",
    "    dinamic_df = pd.read_sql(text(f\"SELECT * FROM {table}\"), conn)\n",
    "\n",
    "    # limpiar\n",
    "    clean_df = dinamic_df[dinamic_df.isnull().mean(axis=1) <= 0.50]\n",
    "\n",
    "    # detectar nulos\n",
    "    deleted_rows = len(dinamic_df) - len(clean_df)\n",
    "    print(f\"[{table}] Filas eliminadas por nulos: {deleted_rows}\")\n",
    "\n",
    "    return dinamic_df, clean_df\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "\n",
    "    for table in table_list[\"table_name\"]:\n",
    "\n",
    "        print(f\"\\n=== Procesando tabla: {table} ===\")\n",
    "\n",
    "        original_df, clean_df = cleaner(table)\n",
    "\n",
    "        # obtener primary key\n",
    "        pk = get_primary_key(table)\n",
    "\n",
    "        if pk is None:\n",
    "            print(f\"No PK en tabla {table}, saltando…\")\n",
    "            continue\n",
    "\n",
    "        # identificar IDs eliminados\n",
    "        deleted_ids = set(original_df[pk]) - set(clean_df[pk])\n",
    "\n",
    "        # borrar filas sucias\n",
    "        delete_rows(table, pk, deleted_ids)\n",
    "\n",
    "        # reinsertar las filas limpias\n",
    "        insert_clean_rows(table, clean_df)\n",
    "\n",
    "        print(f\"✔ Tabla {table} actualizada correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
