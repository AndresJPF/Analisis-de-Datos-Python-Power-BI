{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4ead37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ciudad       fecha producto      tipo_producto  cantidad  \\\n",
      "0                santiago  2025-10-30    arepa          abarrotes       2.0   \n",
      "1                 cordoba  2025-11-17    arepa          abarrotes       7.0   \n",
      "2            barranquilla  2025-10-22    leche             lacteo       9.0   \n",
      "3                new york  2025-10-20   cereal             lacteo       3.0   \n",
      "4                  madrid  2025-10-20    leche              hogar       2.0   \n",
      "...                   ...         ...      ...                ...       ...   \n",
      "1048570       guadalajara  2025-10-23   yogurt             lacteo       9.0   \n",
      "1048571  ciudad de mexico  2025-11-13  gaseosa              hogar       7.0   \n",
      "1048572              lima  2025-10-30    arepa             bebida       8.0   \n",
      "1048573            madrid  2025-10-23     cafe          abarrotes      10.0   \n",
      "1048574             cusco  2025-10-22    queso  alimentopercedero       1.0   \n",
      "\n",
      "         precio_unitario tipo_de_venta tipo_cliente  descuento  costo_envio  \\\n",
      "0                 3681.0        online    minorista       0.20          0.0   \n",
      "1                 2321.0  distribuidor     gobierno       0.15          0.0   \n",
      "2                 3540.0  distribuidor     gobierno       0.20          0.0   \n",
      "3                 3287.0  tiendafisica     gobierno       0.05          0.0   \n",
      "4                 3414.0  distribuidor    mayorista       0.00          0.0   \n",
      "...                  ...           ...          ...        ...          ...   \n",
      "1048570           4325.0        online    mayorista       0.05          0.0   \n",
      "1048571           1187.0  tiendafisica     gobierno       0.15          0.0   \n",
      "1048572           3575.0           NaN  corporativo       0.10          0.0   \n",
      "1048573           2073.0        online  corporativo       0.00          0.0   \n",
      "1048574           1192.0    callcenter    minorista       0.00          0.0   \n",
      "\n",
      "         total_venta  \n",
      "0            5889.60  \n",
      "1           13809.95  \n",
      "2           25488.00  \n",
      "3            9367.95  \n",
      "4            6828.00  \n",
      "...              ...  \n",
      "1048570     36978.75  \n",
      "1048571      7062.65  \n",
      "1048572     25740.00  \n",
      "1048573     20730.00  \n",
      "1048574      1192.00  \n",
      "\n",
      "[1048575 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "df_test = pd.read_csv(\"../ventas_limpias.csv\")\n",
    "\n",
    "print(df_test)\n",
    "# [1.048.574  rows x 11 columns]\n",
    "# 11 Columnas\n",
    "# 1.048.575 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcabc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Succesfull!!\n"
     ]
    }
   ],
   "source": [
    "#Carga el archivo .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "#Variables de entorno\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(URL)\n",
    "\n",
    "conn = engine.connect()\n",
    "try:\n",
    "    print(\"Connection Succesfull!!\" if conn else \"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error al conectar la base datos en\", e)\n",
    "    \n",
    "set = conn.execute(text(\"SET search_path TO riwi_ventas\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb08dbf",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef7975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables founded\n",
      "1. tipo_producto\n",
      "2. producto\n",
      "3. ciudad\n",
      "4. factura_ventas\n",
      "5. tipo_venta\n",
      "6. tipo_cliente\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    # Establecer el schema\n",
    "    conn.execute(text(\"SET search_path TO riwi_ventas\"))\n",
    "    \n",
    "    # 1. Get tables list en schema\n",
    "    table_list = pd.read_sql(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'riwi_ventas';\"), conn)\n",
    "\n",
    "    print(\"Tables founded\")\n",
    "\n",
    "    idx = 0\n",
    "       \n",
    "    for table in table_list[\"table_name\"]:\n",
    "        idx +=1\n",
    "        print(f\"{idx}. {table}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6395f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- tipo_producto: exist and is filled!.\n",
      "\n",
      "- producto: exist and is filled!.\n",
      "\n",
      "- ciudad: exist and is filled!.\n",
      "\n",
      "- factura_ventas: exist and is filled!.\n",
      "\n",
      "- tipo_venta: exist and is filled!.\n",
      "\n",
      "- tipo_cliente: exist and is filled!.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET search_path TO riwi_ventas\"))\n",
    "    for table in table_list[\"table_name\"]:\n",
    "        verify = pd.read_sql(text(f\"SELECT * FROM {table} limit 1000;\"),conn)\n",
    "\n",
    "        if not verify.empty:\n",
    "            print(f\"- {table}: exist and is filled!.\\n\")\n",
    "        else:\n",
    "            print(f\"- {table}: doesn't exist or is empty.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b0e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing table: tipo_producto\n",
      "Original rows: 7\n",
      "Null values found: 1\n",
      "Rows removed: 1\n",
      "Clean rows: 6\n",
      "Deleting old data...\n",
      "Error processing tipo_producto: (psycopg2.errors.ForeignKeyViolation) update or delete on table \"tipo_producto\" violates foreign key constraint \"producto_tipo_producto_id_fkey\" on table \"producto\"\n",
      "DETAIL:  Key (tipo_producto_id)=(1) is still referenced from table \"producto\".\n",
      "\n",
      "[SQL: DELETE FROM riwi_ventas.\"tipo_producto\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "\n",
      "Processing table: producto\n",
      "Error processing producto: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "[SQL: SELECT * FROM riwi_ventas.\"producto\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/2j85)\n",
      "\n",
      "Processing table: ciudad\n",
      "Error processing ciudad: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "[SQL: SELECT * FROM riwi_ventas.\"ciudad\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/2j85)\n",
      "\n",
      "Processing table: factura_ventas\n",
      "Error processing factura_ventas: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "[SQL: SELECT * FROM riwi_ventas.\"factura_ventas\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/2j85)\n",
      "\n",
      "Processing table: tipo_venta\n",
      "Error processing tipo_venta: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "[SQL: SELECT * FROM riwi_ventas.\"tipo_venta\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/2j85)\n",
      "\n",
      "Processing table: tipo_cliente\n",
      "Error processing tipo_cliente: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "[SQL: SELECT * FROM riwi_ventas.\"tipo_cliente\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/2j85)\n",
      "\n",
      "All tables processed successfully!\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    # Set the schema\n",
    "    conn.execute(text(\"SET search_path TO riwi_ventas\"))\n",
    "    \n",
    "    # 1. Get tables\n",
    "    table_list = pd.read_sql(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'riwi_ventas';\"), conn)\n",
    "    \n",
    "    # 2. Process each table\n",
    "    for table in table_list[\"table_name\"]:\n",
    "        print(f\"\\nProcessing table: {table}\")\n",
    "        \n",
    "        try:\n",
    "            # Read the complete table\n",
    "            query = text(f'SELECT * FROM riwi_ventas.\"{table}\"')\n",
    "            df = pd.read_sql(query, conn)\n",
    "            \n",
    "            print(f\"Original rows: {len(df):,}\")\n",
    "            \n",
    "            # Count nulls BEFORE\n",
    "            nulls_before = df.isnull().sum().sum()\n",
    "            if nulls_before > 0:\n",
    "                print(f\"Null values found: {nulls_before:,}\")\n",
    "            \n",
    "            # Delete all rows with any null value\n",
    "            clean_df = df.dropna()\n",
    "            \n",
    "            # Calculate removed rows\n",
    "            removed_rows = len(df) - len(clean_df)\n",
    "            \n",
    "            print(f\"Rows removed: {removed_rows:,}\")\n",
    "            print(f\"Clean rows: {len(clean_df):,}\")\n",
    "            \n",
    "            if removed_rows > 0:\n",
    "                # 3. Delete ALL data from table\n",
    "                print(f\"Deleting old data...\")\n",
    "                conn.execute(text(f'DELETE FROM riwi_ventas.\"{table}\"'))\n",
    "                \n",
    "                # 4. Insert clean data by chunks\n",
    "                CHUNK_SIZE = 10000 \n",
    "                \n",
    "                # Read clean data by chunks\n",
    "                for i in range(0, len(clean_df), CHUNK_SIZE):\n",
    "                    # Get chunk\n",
    "                    chunk = clean_df.iloc[i:i + CHUNK_SIZE]\n",
    "                    \n",
    "                    # Replace NaN with None for SQL\n",
    "                    chunk = chunk.where(pd.notnull(chunk), None)\n",
    "                    \n",
    "                    # Get column names\n",
    "                    cols = chunk.columns.tolist()\n",
    "                    colnames = \", \".join([f'\"{c}\"' for c in cols])\n",
    "                    placeholders = \", \".join([f\":{c}\" for c in cols])\n",
    "                    \n",
    "                    # Create query\n",
    "                    query = text(f\"\"\"\n",
    "                        INSERT INTO riwi_ventas.\"{table}\" ({colnames})\n",
    "                        VALUES ({placeholders});\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    # Execute all rows in chunk\n",
    "                    conn.execute(query, chunk.to_dict(orient=\"records\"))\n",
    "                    \n",
    "                    print(f\"Chunk {i//CHUNK_SIZE + 1} inserted ({len(chunk)} rows)\")\n",
    "                \n",
    "                print(f\"Table {table} was inserted successfully!\")\n",
    "            else:\n",
    "                print(f\"Table {table} was already clean, no changes\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {table}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Commit all changes\n",
    "    conn.commit()\n",
    "\n",
    "print(\"\\nAll tables processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86984808",
   "metadata": {},
   "source": [
    "# **REPORTE DE CALIDAD DE DATOS**\n",
    "\n",
    "## **RESUMEN GENERAL**\n",
    "\n",
    "| ASPECTO | VALOR | OBSERVACIONES | CALIFICACION |\n",
    "|---------|-------|---------------|--------------|\n",
    "| Total Tablas Analizadas | 6 tablas | Todas las tablas del schema riwi_ventas | COMPLETO |\n",
    "| Total Registros | 1,048,745 registros | Suma de todas las filas de todas las tablas | ALTO VOLUMEN |\n",
    "| Registros con Problemas | 1,154 registros | Aproximadamente 0.11% del total | BUENA CALIDAD |\n",
    "| Tablas con Problemas | 4 de 6 tablas | 66% de las tablas tienen algun problema | ATENCION REQUERIDA |\n",
    "| Principal Problema | Valores Nulos | 1,146 nulos en fechas de ventas | PROBLEMA CRITICO |\n",
    "\n",
    "---\n",
    "\n",
    "## **DETALLE POR TABLA**\n",
    "\n",
    "| NOMBRE TABLA | TOTAL FILAS | FILAS CON PROBLEMAS | % PROBLEMAS | TIPO DE PROBLEMA | RECOMENDACION |\n",
    "|--------------|-------------|---------------------|-------------|------------------|---------------|\n",
    "| factura_ventas | 1,048,575 | 1,146 | 0.11% | Fechas nulas (1,146) | ELIMINAR registros |\n",
    "| ciudad | 34 | 1 | 2.94% | Nombre ciudad nulo | Completar manualmente |\n",
    "| producto | 90 | 6 | 6.67% | Nombre producto nulo | Completar manualmente |\n",
    "| tipo_cliente | 5 | 0 | 0.00% | Sin problemas | MANTENER |\n",
    "| tipo_producto | 7 | 1 | 14.29% | Tipo producto nulo | Completar manualmente |\n",
    "| tipo_venta | 5 | 1 | 20.00% | Tipo venta nulo | Completar manualmente |\n",
    "\n",
    "**ESCALA DE CALIDAD:**\n",
    "- 0-1% = EXCELENTE\n",
    "- 1-5% = ACEPTABLE  \n",
    "- 5-10% = REGULAR\n",
    "- 10% = CRITICO\n",
    "\n",
    "---\n",
    "\n",
    "## **TIPOS DE PROBLEMAS ENCONTRADOS**\n",
    "\n",
    "| TIPO DE PROBLEMA | CANTIDAD | % DEL TOTAL | TABLAS AFECTADAS | GRAVEDAD |\n",
    "|------------------|----------|-------------|------------------|----------|\n",
    "| Valores Nulos | 1,155 | 99.9% | factura_ventas, ciudad, producto, tipo_producto, tipo_venta | ALTA |\n",
    "| Duplicados | 0 | 0% | Ninguna | NULA |\n",
    "| Formatos Incorrectos | 0 | 0% | Ninguna | NULA |\n",
    "| Valores Fuera de Rango | 0 | 0% | Ninguna | NULA |\n",
    "| Relaciones Rotas | 0 | 0% | Ninguna | NULA |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
